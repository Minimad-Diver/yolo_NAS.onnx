name: Export YOLO-NAS Pretrained (ONNX)

on:
  workflow_dispatch:
    inputs:
      model_size:
        description: "YOLO-NAS size: s, m, l"
        required: true
        default: "s"
      input_size:
        description: "Model input size (e.g. 320 or 640)"
        required: true
        default: "320"

jobs:
  export:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install super_gradients==3.7.1
          pip install torch
          pip install onnx==1.15.0 onnxsim

      - name: Patch super_gradients weight host
        run: |
          python - << 'PY'
          import importlib
          import pathlib
          import sys

          # Find where super_gradients is installed
          sg = importlib.import_module("super_gradients")
          sg_root = pathlib.Path(sg.__file__).resolve().parent
          print("super_gradients root:", sg_root)

          # Search for files that contain the old host string
          old = "sghub.deci.ai"
          new = "sg-hub-nv.s3.amazonaws.com"

          patched = 0
          for path in sg_root.rglob("*.py"):
            txt = path.read_text(errors="ignore")
            if old in txt:
              path.write_text(txt.replace(old, new))
              print("Patched:", path)
              patched += 1

          if patched == 0:
            print("No files needed patching (old host string not found).")
          else:
            print(f"Patched {patched} file(s).")
          PY

      - name: Export model to ONNX (legacy exporter)
        run: |
          python - << 'PY'
          import os
          import torch
          import onnx

          from super_gradients.common.object_names import Models
          from super_gradients.training import models

          model_size = os.environ.get("MODEL_SIZE", "s").lower()
          input_size = int(os.environ.get("INPUT_SIZE", "320"))

          model_map = {
            "s": Models.YOLO_NAS_S,
            "m": Models.YOLO_NAS_M,
            "l": Models.YOLO_NAS_L,
          }

          if model_size not in model_map:
            raise SystemExit("MODEL_SIZE must be one of: s, m, l")

          out_name = f"yolo_nas_{model_size}_{input_size}.onnx"

          model = models.get(model_map[model_size], pretrained_weights="coco")
          model.eval()

          dummy = torch.randn(1, 3, input_size, input_size)

          # Force legacy exporter (avoids onnxscript dependency)
          torch.onnx.export(
            model,
            dummy,
            out_name,
            opset_version=17,
            input_names=["images"],
            output_names=["outputs"],
            do_constant_folding=True,
          )

          m = onnx.load(out_name)
          onnx.checker.check_model(m)
          print("Exported:", out_name)
          PY
        env:
          MODEL_SIZE: ${{ inputs.model_size }}
          INPUT_SIZE: ${{ inputs.input_size }}

      - name: Upload ONNX artifact
        uses: actions/upload-artifact@v4
        with:
          name: yolo-nas-onnx
          path: "*.onnx"
